{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOC2reZJNCc0/IIWXt2/WlB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fendpray18/NLP/blob/master/NLP%20Basic%20Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTMckNeLbxaB",
        "colab_type": "text"
      },
      "source": [
        "#Tutorial Basic NLP\n",
        "\n",
        "As we know that NLP (natural language processing) is used to do for text processing. There are few step/techincal that we can understand :\n",
        "\n",
        "\n",
        "1.   Case Folding\n",
        "2.   Tokenizing\n",
        "3.   Filtering & Stemming\n",
        "\n",
        "Text processing using a tool library with NLTK.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4cIhs7mNlQn",
        "colab_type": "text"
      },
      "source": [
        "#First Step : Downloading NLTK Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "682hcpQcLFj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "465c1f61-eb9d-4749-d886-bbfa9e435804"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuYxYT-gLjuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b67e7a3e-9557-4df0-a49d-216a682d11ed"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet') #call the nltk downloader\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g627mf7nbjA",
        "colab_type": "text"
      },
      "source": [
        "#An Example \n",
        "\n",
        "There is no consider to be one by step on this learning. Just ignoring and see the purpose example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dV9OKfwnY5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bed269a1-9c84-4730-dae7-273e079dc786"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer #nltk.stem is a package that performs stemming using different classes\n",
        "wnl = WordNetLemmatizer() #fuction for using lemma (as derived word and root word, ex : ran => run)\n",
        "print(wnl.lemmatize('leaves'))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "leaf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvr6vWoApXzq",
        "colab_type": "text"
      },
      "source": [
        "#Ready to the Text Processing Step\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICSNZGCwpWyU",
        "colab_type": "text"
      },
      "source": [
        "**1. Case Folding**\n",
        "\n",
        "A process to convert text to be standard text. In case for this step, it can be used a function, as lower text / .lower()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GCdqpkqrpN_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e490d283-32f5-47ee-da48-979321df40a5"
      },
      "source": [
        "text = str(input(\"Please write sentence (no need much word, it just can be 5 word maximum) : \"))\n",
        "\n",
        "print(\"\\nInput Text : {} \\n\" .format(text))\n",
        "\n",
        "lower_text = text.lower()\n",
        "print(\"Case Folding Text :\", lower_text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please write sentence (no need much word, it just can be 5 word maximum) : Saya adalah Fendy Prayogi\n",
            "\n",
            " Input Text : Saya adalah Fendy Prayogi \n",
            "\n",
            "Case Folding Text :  saya adalah fendy prayogi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzfaJVkduFEc",
        "colab_type": "text"
      },
      "source": [
        "**2. Tokenizing**\n",
        "\n",
        "In next step, we can change that text to be one by one word or we can know it as \"LIST\". There are 2 function list from tokenizing step :\n",
        "1. Sentence List : function sent_tokenize()\n",
        "2. Word List : function word_tokenize()\n",
        "\n",
        "The differents of these function are convert list into text. In other case, there have funtion to remove text, like removing whitespace, mark text, and number.\n",
        "\n",
        "\n",
        "*   \n",
        "*   List item\n",
        "\n",
        "\n"
      ]
    }
  ]
}